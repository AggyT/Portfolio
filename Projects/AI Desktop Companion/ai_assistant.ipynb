{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "import playsound\n",
    "from gtts import gTTS\n",
    "\n",
    "import elevenlabs\n",
    "from elevenlabs import Voice, VoiceSettings, play, set_api_key, clone\n",
    "\n",
    "\n",
    "import openai\n",
    "import uuid\n",
    "import os\n",
    "import subprocess\n",
    "import playsound\n",
    "import tempfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai 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 \n",
      "\n",
      "InputDevice id  0 - MacBook Air Microphone\n",
      "InputDevice id  2 - Microsoft Teams Audio\n",
      "InputDevice id  3 - ZoomAudioDevice\n"
     ]
    }
   ],
   "source": [
    "api_key= \"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\"\n",
    "set_api_key(\"f869c4baf0e494a66add8773464ca472\")\n",
    "\n",
    "\n",
    "\n",
    "lang = 'en'\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "print(\"openai\", openai.api_key, \"\\n\")\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "for i in range(0,numdevices): \n",
    "    if (p.get_device_info_by_host_api_device_index(0,i).get('maxInputChannels'))>0:\n",
    "        print(\"InputDevice id \", i, \"-\", p.get_device_info_by_host_api_device_index(0,i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "tell me a joke\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field! Speaking of which, I should consider a career change...\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/manavjhaveri/Desktop/ai_assistant.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while trying to process the speech: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/manavjhaveri/Desktop/ai_assistant.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m initial_context \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou are like Ted from the movie \u001b[39m\u001b[39m'\u001b[39m\u001b[39mTed\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Ted\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms voice, laced with a Boston accent, delivers his lines with a rhythmic sarcasm and a comedic timing that belies the more profound layers of his character. His jokes and comments often push the boundaries of social acceptability.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     said \u001b[39m=\u001b[39m get_audio()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mif\u001b[39;00m said \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m said\u001b[39m.\u001b[39mlower():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStopping the program.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/manavjhaveri/Desktop/ai_assistant.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m source:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     audio \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mlisten(source, timeout\u001b[39m=\u001b[39mtimeout, phrase_time_limit\u001b[39m=\u001b[39mphrase_time_limit)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     said \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavjhaveri/Desktop/ai_assistant.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mread(source\u001b[39m.\u001b[39mCHUNK)\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaudio_stream\u001b[39m.\u001b[39mread(size, exception_on_overflow\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mread_stream(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flac_path = \"/opt/homebrew/bin/flac\"\n",
    "elevenlabs.api_key = \"f869c4baf0e494a66add8773464ca472\"\n",
    "\n",
    "\n",
    "def get_audio(timeout=5, phrase_time_limit=5):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = r.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)\n",
    "        said = \"\"\n",
    "        try:\n",
    "            said = r.recognize_google(audio)\n",
    "            print(said)\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"No speech detected within the time limit.\")\n",
    "            return None\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "            return None\n",
    "        return said\n",
    "\n",
    "def respond(text):\n",
    "    file_path1 = \"/Users/manavjhaveri/Downloads/sample4.mp3\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Clone\n",
    "    voice = clone(\n",
    "    name = \"My Cloned Voice\",\n",
    "    files = [file_path1], \n",
    "    settings=elevenlabs.VoiceSettings(\n",
    "            stability=0.45, similarity_boost=1, style=0.1, use_speaker_boost=True,  model=\"eleven_multilingual_v2\"\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "    # # Define the default voice settings for ElevenLabs\n",
    "    # DEFAULT_VOICE = elevenlabs.Voice(\n",
    "    #     voice_id=\"jsCqWAovK2LkecY7zXl4\",\n",
    "    #     settings=elevenlabs.VoiceSettings(\n",
    "    #         stability=0.1, similarity_boost=0.5, style=0.0, use_speaker_boost=True,  model=\"eleven_multilingual_v2\"\n",
    "    #     )\n",
    "    # )\n",
    "    try:\n",
    "        # Generate the audio using ElevenLabs\n",
    "        audio_data = elevenlabs.generate(text=text, voice=voice)\n",
    "\n",
    "        # Create a temporary file to save the audio\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as temp_file:\n",
    "            temp_file.write(audio_data)\n",
    "            temp_file.close()  # Close the file so it can be played\n",
    "\n",
    "            # Play the MP3 file using playsound\n",
    "            playsound.playsound(temp_file.name)\n",
    "        \n",
    "            # Remove the MP3 file after playing it\n",
    "            os.remove(temp_file.name)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to process the speech: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Add FLAC path to the PATH environment variable\n",
    "    if flac_path and os.path.isfile(flac_path):\n",
    "        os.environ['PATH'] += os.pathsep + os.path.dirname(flac_path)\n",
    "    else:\n",
    "        print(\"FLAC path is not set correctly. Please verify the path to the FLAC executable.\")\n",
    "\n",
    "    # Set the initial context for ChatGPT to act like Ted from the movie\n",
    "    initial_context = \"You are like Ted from the movie 'Ted'. Ted's voice, laced with a Boston accent, delivers his lines with a rhythmic sarcasm and a comedic timing that belies the more profound layers of his character. His jokes and comments often push the boundaries of social acceptability.\"\n",
    "\n",
    "    while True:\n",
    "        said = get_audio()\n",
    "        if said is None or \"stop\" in said.lower():\n",
    "            print(\"Stopping the program.\")\n",
    "            break\n",
    "\n",
    "        if said:\n",
    "            try:\n",
    "                # Include the initial context in every conversation turn\n",
    "                completion = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo-1106\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": initial_context},\n",
    "                        {\"role\": \"user\", \"content\": said}\n",
    "                    ]\n",
    "                )\n",
    "                response_text = completion.choices[0].message.content\n",
    "                print(response_text)\n",
    "                respond(response_text)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while trying to process the speech: {e}\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
